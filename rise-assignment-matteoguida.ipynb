{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30588,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Import all necessary libraries\n\nimport transformers\nimport torch\nimport datasets\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom sklearn.model_selection import train_test_split\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import BertTokenizer, BertConfig, BertForTokenClassification, AutoTokenizer, AutoModelForTokenClassification, DataCollatorForTokenClassification\nfrom datasets import load_dataset, load_metric, DatasetDict\nfrom transformers import TrainingArguments, Trainer","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-04T21:36:34.544788Z","iopub.execute_input":"2023-12-04T21:36:34.545069Z","iopub.status.idle":"2023-12-04T21:36:50.267933Z","shell.execute_reply.started":"2023-12-04T21:36:34.545006Z","shell.execute_reply":"2023-12-04T21:36:50.267136Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"# Activate GPU for training \n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2023-12-04T21:36:50.269655Z","iopub.execute_input":"2023-12-04T21:36:50.270637Z","iopub.status.idle":"2023-12-04T21:36:50.298938Z","shell.execute_reply.started":"2023-12-04T21:36:50.270601Z","shell.execute_reply":"2023-12-04T21:36:50.297886Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"# We needed to install the evaluation metric for this task\n\n!pip install seqeval","metadata":{"execution":{"iopub.status.busy":"2023-12-04T21:36:50.300202Z","iopub.execute_input":"2023-12-04T21:36:50.300537Z","iopub.status.idle":"2023-12-04T21:37:05.930194Z","shell.execute_reply.started":"2023-12-04T21:36:50.300504Z","shell.execute_reply":"2023-12-04T21:37:05.928888Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Collecting seqeval\n  Downloading seqeval-1.2.2.tar.gz (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from seqeval) (1.24.3)\nRequirement already satisfied: scikit-learn>=0.21.3 in /opt/conda/lib/python3.10/site-packages (from seqeval) (1.2.2)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval) (1.11.3)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval) (1.3.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval) (3.2.0)\nBuilding wheels for collected packages: seqeval\n  Building wheel for seqeval (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=18b10386717b4845a1e139f7084727c0f879766ac59422b63b9e4112ce5a1db7\n  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\nSuccessfully built seqeval\nInstalling collected packages: seqeval\nSuccessfully installed seqeval-1.2.2\n","output_type":"stream"}]},{"cell_type":"code","source":"# Import the dataset directly from HuggingFace\n\nmultinerd = load_dataset(\"Babelscape/multinerd\")","metadata":{"execution":{"iopub.status.busy":"2023-12-04T21:37:05.933363Z","iopub.execute_input":"2023-12-04T21:37:05.934149Z","iopub.status.idle":"2023-12-04T21:37:34.132807Z","shell.execute_reply.started":"2023-12-04T21:37:05.934102Z","shell.execute_reply":"2023-12-04T21:37:34.131923Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Downloading and preparing dataset json/Babelscape--multinerd to /root/.cache/huggingface/datasets/json/Babelscape--multinerd-d3bf0284fd817c7b/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"17b3f4ec76944f64beeb677c81f50067"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/32.7M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"579d90cdca4c48fcb8b35081d7e0060a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/37.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9c6125e5e3b54985b35a3cbbaaf40c26"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/46.0M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6b26c34ccfe44037955925b217d32769"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/46.2M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"668010ef8237478694035f4181da4d4a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/50.1M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eb264000037c4fc8aa711c8856c7a5b6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/34.1M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b8b09657eeb4e8da1f92d5979741c4d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/38.6M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"da74f536b4fe44f9a4696f0e95c94829"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/44.0M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"19ae36064de045cbb08246b3816e4cbb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/42.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e01a9ebac0dc4ab9a79c0be20c072ee8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/60.4M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"33801d72890e46209854c9198662d41f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/4.22M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"83a3d850db1a4d9cab838b6968279a78"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/4.65M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a549ebaf85b4b77921423c9073fb81e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/5.85M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bb43e0c4827a469f88d25d48aef46bef"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/6.28M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"996a35efbf9b4b6d88192bdf20d7e5d0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/6.51M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"645a489dd78c4620b936a81fd6d79490"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/4.29M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c8d690841741484fac60b4e6bc7ed428"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/4.82M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"38dc29ec5bae428b9207c1be3ed06be8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/5.25M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f0f44196c3ba49c5a9c36d92a33eb2e6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/5.28M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f3a6f25856ac4dd9868ece2985f63c9e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/7.47M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9246da9a2fe04884af55b7efefe004fa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c35533e774664ee9be4c4a175ca1ad0b"}},"metadata":{}},{"name":"stdout","text":"Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/Babelscape--multinerd-d3bf0284fd817c7b/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a976bbb22b824f5189707275c6c9e61a"}},"metadata":{}}]},{"cell_type":"code","source":"# Originally, two segments - train and test. Each segment contains tokens, ner_tags and information about language\nmultinerd","metadata":{"execution":{"iopub.status.busy":"2023-12-04T21:37:34.133936Z","iopub.execute_input":"2023-12-04T21:37:34.134251Z","iopub.status.idle":"2023-12-04T21:37:34.141232Z","shell.execute_reply.started":"2023-12-04T21:37:34.134225Z","shell.execute_reply":"2023-12-04T21:37:34.140415Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['tokens', 'ner_tags', 'lang'],\n        num_rows: 1339200\n    })\n    test: Dataset({\n        features: ['tokens', 'ner_tags', 'lang'],\n        num_rows: 167993\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"# Checking the dimensions of data\n\nmultinerd.shape","metadata":{"execution":{"iopub.status.busy":"2023-12-04T21:37:34.142549Z","iopub.execute_input":"2023-12-04T21:37:34.142913Z","iopub.status.idle":"2023-12-04T21:37:34.151391Z","shell.execute_reply.started":"2023-12-04T21:37:34.142888Z","shell.execute_reply":"2023-12-04T21:37:34.150554Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"{'train': (1339200, 3), 'test': (167993, 3)}"},"metadata":{}}]},{"cell_type":"code","source":"# Filter out the non-English examples\n\nmultinerd = multinerd.filter(lambda sample: sample['lang'] == 'en')","metadata":{"execution":{"iopub.status.busy":"2023-12-04T21:37:34.152500Z","iopub.execute_input":"2023-12-04T21:37:34.152785Z","iopub.status.idle":"2023-12-04T21:38:59.254405Z","shell.execute_reply.started":"2023-12-04T21:37:34.152760Z","shell.execute_reply":"2023-12-04T21:38:59.253401Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1340 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f26bc2df6fa348fa9cb2950afa87e6f1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/168 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"68d6f9056a5641acbe9cf093288eab93"}},"metadata":{}}]},{"cell_type":"code","source":"# Manually create a val set from training set, while maintaining train and test in their original form\n\ntrain_dataset = multinerd['train']\ntest_dataset = multinerd['test']\n\nsplit_ratio = 0.8\nnum_train_samples = int(len(train_dataset) * split_ratio)\n\ntrain_set = train_dataset.select(list(range(num_train_samples)))\nval_set = train_dataset.select(list(range(num_train_samples, len(train_dataset))))\n\n# Update the DatasetDict with the sets\nmultinerd = DatasetDict({\n    'train': train_set,\n    'valid': val_set,\n    'test': test_dataset\n})","metadata":{"execution":{"iopub.status.busy":"2023-12-04T21:38:59.255744Z","iopub.execute_input":"2023-12-04T21:38:59.256145Z","iopub.status.idle":"2023-12-04T21:38:59.796456Z","shell.execute_reply.started":"2023-12-04T21:38:59.256105Z","shell.execute_reply":"2023-12-04T21:38:59.795674Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"multinerd","metadata":{"execution":{"iopub.status.busy":"2023-12-04T21:38:59.797511Z","iopub.execute_input":"2023-12-04T21:38:59.797812Z","iopub.status.idle":"2023-12-04T21:38:59.803993Z","shell.execute_reply.started":"2023-12-04T21:38:59.797786Z","shell.execute_reply":"2023-12-04T21:38:59.802942Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['tokens', 'ner_tags', 'lang'],\n        num_rows: 105024\n    })\n    valid: Dataset({\n        features: ['tokens', 'ner_tags', 'lang'],\n        num_rows: 26256\n    })\n    test: Dataset({\n        features: ['tokens', 'ner_tags', 'lang'],\n        num_rows: 16454\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"# For this task, we aim for the cased base BERT tokenizer \n# Cased because capitalization most likely will play an important role in the NER task\n\n# Import the BERT tokenizer\n\n\ntokenizer = AutoTokenizer.from_pretrained('bert-base-cased')","metadata":{"execution":{"iopub.status.busy":"2023-12-04T21:38:59.809108Z","iopub.execute_input":"2023-12-04T21:38:59.809429Z","iopub.status.idle":"2023-12-04T21:39:01.095856Z","shell.execute_reply.started":"2023-12-04T21:38:59.809406Z","shell.execute_reply":"2023-12-04T21:39:01.095068Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading tokenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ca0514c4daee490889ac3f914e99b1f6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4e496211de6e48b7bf442e71119c4f40"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"adac9a56f31e457292e0d175fcb4401c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0356b7a65851410da21b6ec5e7ff27ce"}},"metadata":{}}]},{"cell_type":"code","source":"# Word Piece tokenization of BERT causes mismatch between actual NER tags and tokens\n# As words can be split again by tokenizer (##), as exemplified in the following chunks\n\nexample = train_dataset[123]\nprint(example)\n\ntokenized_example = tokenizer(example['tokens'], is_split_into_words=True)\n\ntokens = tokenizer.convert_ids_to_tokens(tokenized_example['input_ids'])\n\nword_ids = tokenized_example.word_ids()","metadata":{"execution":{"iopub.status.busy":"2023-12-04T21:39:01.096938Z","iopub.execute_input":"2023-12-04T21:39:01.097261Z","iopub.status.idle":"2023-12-04T21:39:01.106272Z","shell.execute_reply.started":"2023-12-04T21:39:01.097236Z","shell.execute_reply":"2023-12-04T21:39:01.105365Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"{'tokens': ['The', 'campaign', 'was', 'organized', ',', 'among', 'others', ',', 'by', 'Abbie', 'Hoffman', '.'], 'ner_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0], 'lang': 'en'}\n","output_type":"stream"}]},{"cell_type":"code","source":"# Mismatch in length\n\nlen(example['ner_tags']), len(tokenized_example['input_ids'])","metadata":{"execution":{"iopub.status.busy":"2023-12-04T21:39:01.107471Z","iopub.execute_input":"2023-12-04T21:39:01.107850Z","iopub.status.idle":"2023-12-04T21:39:01.117324Z","shell.execute_reply.started":"2023-12-04T21:39:01.107816Z","shell.execute_reply":"2023-12-04T21:39:01.116447Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"(12, 16)"},"metadata":{}}]},{"cell_type":"code","source":"# This is due to the presence of special tokens and subwords (typical of BERT), as figured in this example\n\ntokens","metadata":{"execution":{"iopub.status.busy":"2023-12-04T21:39:01.118369Z","iopub.execute_input":"2023-12-04T21:39:01.118689Z","iopub.status.idle":"2023-12-04T21:39:01.128492Z","shell.execute_reply.started":"2023-12-04T21:39:01.118656Z","shell.execute_reply":"2023-12-04T21:39:01.127609Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"['[CLS]',\n 'The',\n 'campaign',\n 'was',\n 'organized',\n ',',\n 'among',\n 'others',\n ',',\n 'by',\n 'A',\n '##bb',\n '##ie',\n 'Hoffman',\n '.',\n '[SEP]']"},"metadata":{}}]},{"cell_type":"code","source":"def tokenize_align(example, label_all_tokens=True):\n    '''\n    Tokenize and align the NER labels with the corresponding tokens in a given example.\n\n    Args:\n        example (dict): A dictionary containing 'tokens' and 'ner_tags' for a single example.\n        label_all_tokens (bool, optional): If True, assigns NER labels to all tokens; if False, assigns labels only to the first token of each word.\n\n    Returns:\n        dict: Tokenized input with aligned NER labels.\n\n    Note:\n        Special tokens are marked with -100, and this will be ignored by PyTorch during training.\n        Labels are aligned to their corresponding tokens, considering word boundaries and the label_all_tokens flag.\n\n    '''\n    \n    tokenized_input = tokenizer(example['tokens'], truncation=True, is_split_into_words=True)\n    labels = [] \n    \n    for i, label in enumerate(example['ner_tags']):\n        word_ids = tokenized_input.word_ids(batch_index=i)\n        \n        previous_word_idx = None\n        label_ids = []\n        \n        for word_idx in word_ids:\n            if word_idx is None:\n                label_ids.append(-100)  # Special tokens will be ignored during training\n            \n            elif word_idx != previous_word_idx:\n                label_ids.append(label[word_idx])  # Assign NER label to the token\n            \n            else:\n                # If word_idx is not a special token,\n                # append the NER tag if label_all_tokens is true, else assign -100\n                label_ids.append(label[word_idx] if label_all_tokens else -100)\n                    \n            previous_word_idx = word_idx\n            \n        labels.append(label_ids)\n    \n    # Add processed labels to the tokenized input dictionary\n    tokenized_input['labels'] = labels\n    \n    return tokenized_input","metadata":{"execution":{"iopub.status.busy":"2023-12-04T21:39:01.129469Z","iopub.execute_input":"2023-12-04T21:39:01.129794Z","iopub.status.idle":"2023-12-04T21:39:01.139221Z","shell.execute_reply.started":"2023-12-04T21:39:01.129746Z","shell.execute_reply":"2023-12-04T21:39:01.138273Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"# System A","metadata":{}},{"cell_type":"code","source":"# We apply the logic to entire dataset\n\ntokenized_data = multinerd.map(tokenize_align, batched=True)","metadata":{"execution":{"iopub.status.busy":"2023-12-04T21:39:01.140308Z","iopub.execute_input":"2023-12-04T21:39:01.140896Z","iopub.status.idle":"2023-12-04T21:39:26.922848Z","shell.execute_reply.started":"2023-12-04T21:39:01.140864Z","shell.execute_reply":"2023-12-04T21:39:26.922040Z"},"trusted":true},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/106 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d8a9279e134a4e5aa34e77a07eb0facc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/27 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"83b4483ccc444570aeaddccfa314b152"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/17 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"03b4fafa54884e6ca2b61a4b1491b89e"}},"metadata":{}}]},{"cell_type":"code","source":"# Import model from HuggingFace\n\nmodel_a = AutoModelForTokenClassification.from_pretrained('bert-base-cased', num_labels=31)","metadata":{"execution":{"iopub.status.busy":"2023-12-04T21:39:26.923945Z","iopub.execute_input":"2023-12-04T21:39:26.924265Z","iopub.status.idle":"2023-12-04T21:39:29.543022Z","shell.execute_reply.started":"2023-12-04T21:39:26.924240Z","shell.execute_reply":"2023-12-04T21:39:29.542212Z"},"trusted":true},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"826ed89ab24c4762839a1bd0c955bc3c"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"# We use the data collator to pad tokens so all samples are of same length\n\ndata_collator = DataCollatorForTokenClassification(tokenizer)","metadata":{"execution":{"iopub.status.busy":"2023-12-04T21:39:29.544590Z","iopub.execute_input":"2023-12-04T21:39:29.544992Z","iopub.status.idle":"2023-12-04T21:39:29.550241Z","shell.execute_reply.started":"2023-12-04T21:39:29.544953Z","shell.execute_reply":"2023-12-04T21:39:29.549223Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# Define training parameters\n\ntraining_args_a = TrainingArguments(\n    output_dir=\"./fine_tune_bert_output_a\",\n    evaluation_strategy=\"steps\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    num_train_epochs=3,\n    weight_decay=0.01,\n    #logging_steps = 1000,\n    report_to=\"wandb\",\n    run_name = \"RISE_A\",\n    save_strategy=\"no\"\n)","metadata":{"execution":{"iopub.status.busy":"2023-12-04T21:39:29.551567Z","iopub.execute_input":"2023-12-04T21:39:29.551870Z","iopub.status.idle":"2023-12-04T21:39:29.564409Z","shell.execute_reply.started":"2023-12-04T21:39:29.551845Z","shell.execute_reply":"2023-12-04T21:39:29.563675Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# Create a mapping between indices and tags for readability purposes\n\nlabel_mapping = {\n    0: \"O\",\n    1: \"B-PER\",\n    2: \"I-PER\",\n    3: \"B-ORG\",\n    4: \"I-ORG\",\n    5: \"B-LOC\",\n    6: \"I-LOC\",\n    7: \"B-ANIM\",\n    8: \"I-ANIM\",\n    9: \"B-BIO\",\n    10: \"I-BIO\",\n    11: \"B-CEL\",\n    12: \"I-CEL\",\n    13: \"B-DIS\",\n    14: \"I-DIS\",\n    15: \"B-EVE\",\n    16: \"I-EVE\",\n    17: \"B-FOOD\",\n    18: \"I-FOOD\",\n    19: \"B-INST\",\n    20: \"I-INST\",\n    21: \"B-MEDIA\",\n    22: \"I-MEDIA\",\n    23: \"B-MYTH\",\n    24: \"I-MYTH\",\n    25: \"B-PLANT\",\n    26: \"I-PLANT\",\n    27: \"B-TIME\",\n    28: \"I-TIME\",\n    29: \"B-VEHI\",\n    30: \"I-VEHI\",\n}\n\nlabel_names_mapped = [label_mapping[label] for label in label_mapping]\nlen(label_names_mapped)","metadata":{"execution":{"iopub.status.busy":"2023-12-04T21:39:29.565311Z","iopub.execute_input":"2023-12-04T21:39:29.565642Z","iopub.status.idle":"2023-12-04T21:39:29.576690Z","shell.execute_reply.started":"2023-12-04T21:39:29.565605Z","shell.execute_reply":"2023-12-04T21:39:29.575558Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"31"},"metadata":{}}]},{"cell_type":"code","source":"# seqeval metric from HuggingFace as metrics, which is adequate for chunking tasks such as NER\n\nmetric = datasets.load_metric('seqeval')","metadata":{"execution":{"iopub.status.busy":"2023-12-04T21:39:29.577747Z","iopub.execute_input":"2023-12-04T21:39:29.578077Z","iopub.status.idle":"2023-12-04T21:39:30.273985Z","shell.execute_reply.started":"2023-12-04T21:39:29.577994Z","shell.execute_reply":"2023-12-04T21:39:30.273096Z"},"trusted":true},"execution_count":20,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/2.47k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c494bc7489ff4860b0f1824e046c4deb"}},"metadata":{}}]},{"cell_type":"code","source":"example = train_dataset[144]\nprint(example)\n\nlabels = [label_names_mapped[i] for i in example['ner_tags']]\nlabels","metadata":{"execution":{"iopub.status.busy":"2023-12-04T21:39:30.275304Z","iopub.execute_input":"2023-12-04T21:39:30.275950Z","iopub.status.idle":"2023-12-04T21:39:30.283914Z","shell.execute_reply.started":"2023-12-04T21:39:30.275915Z","shell.execute_reply":"2023-12-04T21:39:30.283015Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"{'tokens': ['However', ',', 'the', 'plans', 'were', 'revived', 'in', 'August', '2017', ',', 'with', 'the', 'announcement', 'that', 'Paul', 'Scheer', 'would', 'be', 'writing', 'the', 'series', '.'], 'ner_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0], 'lang': 'en'}\n","output_type":"stream"},{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"['O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'B-PER',\n 'I-PER',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O']"},"metadata":{}}]},{"cell_type":"code","source":"# Test the metric on a small sample\n\nmetric.compute(predictions=[labels], references=[labels])","metadata":{"execution":{"iopub.status.busy":"2023-12-04T21:39:30.284996Z","iopub.execute_input":"2023-12-04T21:39:30.285293Z","iopub.status.idle":"2023-12-04T21:39:30.301622Z","shell.execute_reply.started":"2023-12-04T21:39:30.285269Z","shell.execute_reply":"2023-12-04T21:39:30.300734Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"{'PER': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n 'overall_precision': 1.0,\n 'overall_recall': 1.0,\n 'overall_f1': 1.0,\n 'overall_accuracy': 1.0}"},"metadata":{}}]},{"cell_type":"code","source":"def compute_metrics_a(eval_preds):\n    \n    '''\n    Custom function for evaluation metrics of the NER task. It computes accuracy, precision, recall, and F1.\n    \n    Parameters:\n        eval_preds: a tuple with predicted logits and true labels\n        \n    Returns:\n        dictionary with defined metrics\n    '''\n    \n    pred_logits, labels = eval_preds\n    pred_logits = np.argmax(pred_logits, axis=2)\n\n    predictions = [\n        [label_mapping[prediction] for (prediction, l) in zip(batch_preds, label) if l != -100] \n        for batch_preds, label in zip(pred_logits, labels)\n    ]\n\n    true_labels = [\n        [label_mapping[l] for (prediction, l) in zip(batch_preds, label) if l != -100] \n        for batch_preds, label in zip(pred_logits, labels)\n    ]\n\n    results = metric.compute(predictions=predictions, references=true_labels)\n\n    return {\n        \"precision\": results[\"overall_precision\"],\n        \"recall\": results[\"overall_recall\"],\n        \"f1\": results[\"overall_f1\"],\n        \"accuracy\": results[\"overall_accuracy\"],\n    }","metadata":{"execution":{"iopub.status.busy":"2023-12-04T21:39:30.302723Z","iopub.execute_input":"2023-12-04T21:39:30.303001Z","iopub.status.idle":"2023-12-04T21:39:30.310901Z","shell.execute_reply.started":"2023-12-04T21:39:30.302967Z","shell.execute_reply":"2023-12-04T21:39:30.309968Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# Train the model\n# NOTE: we train for 3 epochs because of limited GPU access\n# however, it is advised to train for more epochs in a NER task\n\ntrainer_a = Trainer(\n    model=model_a,\n    args=training_args_a,\n    train_dataset=tokenized_data[\"train\"],\n    eval_dataset=tokenized_data[\"valid\"],\n    data_collator=data_collator,\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics_a\n)\n\ntrainer_a.train()","metadata":{"execution":{"iopub.status.busy":"2023-12-04T21:39:30.312100Z","iopub.execute_input":"2023-12-04T21:39:30.312424Z","iopub.status.idle":"2023-12-04T23:22:09.644279Z","shell.execute_reply.started":"2023-12-04T21:39:30.312391Z","shell.execute_reply":"2023-12-04T23:22:09.643232Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.0"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20231204_214138-f5yw6zgy</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/mattdrive/huggingface/runs/f5yw6zgy' target=\"_blank\">RISE_A</a></strong> to <a href='https://wandb.ai/mattdrive/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/mattdrive/huggingface' target=\"_blank\">https://wandb.ai/mattdrive/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/mattdrive/huggingface/runs/f5yw6zgy' target=\"_blank\">https://wandb.ai/mattdrive/huggingface/runs/f5yw6zgy</a>"},"metadata":{}},{"name":"stderr","text":"You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='19692' max='19692' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [19692/19692 1:39:57, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>0.282900</td>\n      <td>0.121350</td>\n      <td>0.847520</td>\n      <td>0.725556</td>\n      <td>0.781810</td>\n      <td>0.961095</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.099300</td>\n      <td>0.104465</td>\n      <td>0.806625</td>\n      <td>0.811590</td>\n      <td>0.809100</td>\n      <td>0.964460</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>0.084700</td>\n      <td>0.095065</td>\n      <td>0.831983</td>\n      <td>0.820897</td>\n      <td>0.826403</td>\n      <td>0.966689</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>0.082800</td>\n      <td>0.092473</td>\n      <td>0.887791</td>\n      <td>0.782459</td>\n      <td>0.831803</td>\n      <td>0.967553</td>\n    </tr>\n    <tr>\n      <td>2500</td>\n      <td>0.075000</td>\n      <td>0.089553</td>\n      <td>0.864478</td>\n      <td>0.821240</td>\n      <td>0.842304</td>\n      <td>0.969598</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>0.072100</td>\n      <td>0.083958</td>\n      <td>0.858553</td>\n      <td>0.829143</td>\n      <td>0.843592</td>\n      <td>0.970074</td>\n    </tr>\n    <tr>\n      <td>3500</td>\n      <td>0.066000</td>\n      <td>0.083640</td>\n      <td>0.845466</td>\n      <td>0.849848</td>\n      <td>0.847651</td>\n      <td>0.970321</td>\n    </tr>\n    <tr>\n      <td>4000</td>\n      <td>0.068600</td>\n      <td>0.080008</td>\n      <td>0.875519</td>\n      <td>0.834267</td>\n      <td>0.854396</td>\n      <td>0.971793</td>\n    </tr>\n    <tr>\n      <td>4500</td>\n      <td>0.064700</td>\n      <td>0.076475</td>\n      <td>0.870606</td>\n      <td>0.856885</td>\n      <td>0.863691</td>\n      <td>0.972998</td>\n    </tr>\n    <tr>\n      <td>5000</td>\n      <td>0.062300</td>\n      <td>0.076157</td>\n      <td>0.868724</td>\n      <td>0.858393</td>\n      <td>0.863528</td>\n      <td>0.972823</td>\n    </tr>\n    <tr>\n      <td>5500</td>\n      <td>0.064500</td>\n      <td>0.074126</td>\n      <td>0.876196</td>\n      <td>0.852373</td>\n      <td>0.864120</td>\n      <td>0.973272</td>\n    </tr>\n    <tr>\n      <td>6000</td>\n      <td>0.061200</td>\n      <td>0.075028</td>\n      <td>0.866054</td>\n      <td>0.870957</td>\n      <td>0.868498</td>\n      <td>0.973413</td>\n    </tr>\n    <tr>\n      <td>6500</td>\n      <td>0.061900</td>\n      <td>0.072678</td>\n      <td>0.873965</td>\n      <td>0.865609</td>\n      <td>0.869767</td>\n      <td>0.974111</td>\n    </tr>\n    <tr>\n      <td>7000</td>\n      <td>0.046000</td>\n      <td>0.080963</td>\n      <td>0.847302</td>\n      <td>0.889123</td>\n      <td>0.867709</td>\n      <td>0.972592</td>\n    </tr>\n    <tr>\n      <td>7500</td>\n      <td>0.044400</td>\n      <td>0.074670</td>\n      <td>0.873317</td>\n      <td>0.869194</td>\n      <td>0.871251</td>\n      <td>0.974191</td>\n    </tr>\n    <tr>\n      <td>8000</td>\n      <td>0.042700</td>\n      <td>0.074566</td>\n      <td>0.879134</td>\n      <td>0.855047</td>\n      <td>0.866923</td>\n      <td>0.973933</td>\n    </tr>\n    <tr>\n      <td>8500</td>\n      <td>0.039400</td>\n      <td>0.076740</td>\n      <td>0.866555</td>\n      <td>0.880847</td>\n      <td>0.873642</td>\n      <td>0.974465</td>\n    </tr>\n    <tr>\n      <td>9000</td>\n      <td>0.044700</td>\n      <td>0.072247</td>\n      <td>0.890603</td>\n      <td>0.866535</td>\n      <td>0.878404</td>\n      <td>0.975525</td>\n    </tr>\n    <tr>\n      <td>9500</td>\n      <td>0.043400</td>\n      <td>0.074364</td>\n      <td>0.882027</td>\n      <td>0.870748</td>\n      <td>0.876351</td>\n      <td>0.975427</td>\n    </tr>\n    <tr>\n      <td>10000</td>\n      <td>0.039800</td>\n      <td>0.071365</td>\n      <td>0.878728</td>\n      <td>0.880802</td>\n      <td>0.879764</td>\n      <td>0.975634</td>\n    </tr>\n    <tr>\n      <td>10500</td>\n      <td>0.044100</td>\n      <td>0.071868</td>\n      <td>0.897265</td>\n      <td>0.860604</td>\n      <td>0.878552</td>\n      <td>0.975459</td>\n    </tr>\n    <tr>\n      <td>11000</td>\n      <td>0.037000</td>\n      <td>0.072532</td>\n      <td>0.886911</td>\n      <td>0.868044</td>\n      <td>0.877376</td>\n      <td>0.975465</td>\n    </tr>\n    <tr>\n      <td>11500</td>\n      <td>0.043400</td>\n      <td>0.070678</td>\n      <td>0.860835</td>\n      <td>0.900238</td>\n      <td>0.880095</td>\n      <td>0.975065</td>\n    </tr>\n    <tr>\n      <td>12000</td>\n      <td>0.040100</td>\n      <td>0.068943</td>\n      <td>0.872924</td>\n      <td>0.889616</td>\n      <td>0.881191</td>\n      <td>0.975558</td>\n    </tr>\n    <tr>\n      <td>12500</td>\n      <td>0.043200</td>\n      <td>0.068773</td>\n      <td>0.868614</td>\n      <td>0.896577</td>\n      <td>0.882374</td>\n      <td>0.975682</td>\n    </tr>\n    <tr>\n      <td>13000</td>\n      <td>0.040200</td>\n      <td>0.072166</td>\n      <td>0.861551</td>\n      <td>0.904630</td>\n      <td>0.882565</td>\n      <td>0.975666</td>\n    </tr>\n    <tr>\n      <td>13500</td>\n      <td>0.029900</td>\n      <td>0.075705</td>\n      <td>0.879340</td>\n      <td>0.886538</td>\n      <td>0.882924</td>\n      <td>0.975946</td>\n    </tr>\n    <tr>\n      <td>14000</td>\n      <td>0.029000</td>\n      <td>0.074108</td>\n      <td>0.878871</td>\n      <td>0.890228</td>\n      <td>0.884513</td>\n      <td>0.976215</td>\n    </tr>\n    <tr>\n      <td>14500</td>\n      <td>0.025500</td>\n      <td>0.076390</td>\n      <td>0.881987</td>\n      <td>0.885597</td>\n      <td>0.883789</td>\n      <td>0.976107</td>\n    </tr>\n    <tr>\n      <td>15000</td>\n      <td>0.026000</td>\n      <td>0.077430</td>\n      <td>0.876237</td>\n      <td>0.891618</td>\n      <td>0.883860</td>\n      <td>0.976003</td>\n    </tr>\n    <tr>\n      <td>15500</td>\n      <td>0.028900</td>\n      <td>0.079311</td>\n      <td>0.874348</td>\n      <td>0.893888</td>\n      <td>0.884010</td>\n      <td>0.976083</td>\n    </tr>\n    <tr>\n      <td>16000</td>\n      <td>0.026100</td>\n      <td>0.074398</td>\n      <td>0.874100</td>\n      <td>0.897369</td>\n      <td>0.885582</td>\n      <td>0.976230</td>\n    </tr>\n    <tr>\n      <td>16500</td>\n      <td>0.024800</td>\n      <td>0.079318</td>\n      <td>0.880181</td>\n      <td>0.889556</td>\n      <td>0.884844</td>\n      <td>0.976320</td>\n    </tr>\n    <tr>\n      <td>17000</td>\n      <td>0.025400</td>\n      <td>0.076993</td>\n      <td>0.875357</td>\n      <td>0.896712</td>\n      <td>0.885906</td>\n      <td>0.976404</td>\n    </tr>\n    <tr>\n      <td>17500</td>\n      <td>0.024100</td>\n      <td>0.076108</td>\n      <td>0.878072</td>\n      <td>0.895203</td>\n      <td>0.886555</td>\n      <td>0.976640</td>\n    </tr>\n    <tr>\n      <td>18000</td>\n      <td>0.024300</td>\n      <td>0.078170</td>\n      <td>0.877749</td>\n      <td>0.895621</td>\n      <td>0.886595</td>\n      <td>0.976584</td>\n    </tr>\n    <tr>\n      <td>18500</td>\n      <td>0.025200</td>\n      <td>0.076541</td>\n      <td>0.883350</td>\n      <td>0.891334</td>\n      <td>0.887324</td>\n      <td>0.976700</td>\n    </tr>\n    <tr>\n      <td>19000</td>\n      <td>0.024100</td>\n      <td>0.077235</td>\n      <td>0.880941</td>\n      <td>0.893799</td>\n      <td>0.887323</td>\n      <td>0.976587</td>\n    </tr>\n    <tr>\n      <td>19500</td>\n      <td>0.025600</td>\n      <td>0.076580</td>\n      <td>0.880377</td>\n      <td>0.894292</td>\n      <td>0.887280</td>\n      <td>0.976659</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=19692, training_loss=0.0518820724084371, metrics={'train_runtime': 6153.7438, 'train_samples_per_second': 51.2, 'train_steps_per_second': 3.2, 'total_flos': 9103295020508832.0, 'train_loss': 0.0518820724084371, 'epoch': 3.0})"},"metadata":{}}]},{"cell_type":"code","source":"# Evaluate on test set \n\nresults = trainer_a.predict(tokenized_data[\"test\"])","metadata":{"execution":{"iopub.status.busy":"2023-12-04T23:22:09.645636Z","iopub.execute_input":"2023-12-04T23:22:09.645965Z","iopub.status.idle":"2023-12-04T23:23:01.269764Z","shell.execute_reply.started":"2023-12-04T23:22:09.645939Z","shell.execute_reply":"2023-12-04T23:23:01.268507Z"},"trusted":true},"execution_count":25,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}}]},{"cell_type":"code","source":"pred_logits, labels = results.predictions, results.label_ids\npred_logits = np.argmax(pred_logits, axis=2)\n\n# Flatten the predictions and true labels\nflat_true_labels = [label for sequence_labels in labels for label in sequence_labels]\nflat_pred_labels = [label for sequence_labels in pred_logits for label in sequence_labels]\n\n# Ignore special tokens (-100) during evaluation\nvalid_indices = [index for index, label in enumerate(flat_true_labels) if label != -100]\n\n# Use the sklearn classification_report function with label_mapping\nreport = classification_report(\n    np.array(flat_true_labels)[valid_indices],\n    np.array(flat_pred_labels)[valid_indices],\n    target_names=label_names_mapped\n)\n\nprint(report)","metadata":{"execution":{"iopub.status.busy":"2023-12-04T23:23:01.271262Z","iopub.execute_input":"2023-12-04T23:23:01.271597Z","iopub.status.idle":"2023-12-04T23:23:03.692096Z","shell.execute_reply.started":"2023-12-04T23:23:01.271568Z","shell.execute_reply":"2023-12-04T23:23:03.690879Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           O       0.99      0.99      0.99    329987\n       B-PER       0.99      0.99      0.99      7354\n       I-PER       1.00      1.00      1.00     11509\n       B-ORG       0.98      0.98      0.98      5131\n       I-ORG       0.99      0.98      0.99      5693\n       B-LOC       1.00      1.00      1.00     19489\n       I-LOC       0.99      1.00      0.99      7129\n      B-ANIM       0.74      0.79      0.77      3351\n      I-ANIM       0.71      0.78      0.75      1658\n       B-BIO       0.49      0.88      0.63        34\n       I-BIO       0.00      0.00      0.00         0\n       B-CEL       0.83      0.88      0.85        56\n       I-CEL       0.85      0.77      0.81        22\n       B-DIS       0.79      0.82      0.81      2014\n       I-DIS       0.78      0.80      0.79       917\n       B-EVE       0.95      0.96      0.95       451\n       I-EVE       0.95      0.97      0.96       667\n      B-FOOD       0.72      0.68      0.70      1107\n      I-FOOD       0.65      0.59      0.62       234\n      B-INST       0.56      0.80      0.66        25\n      I-INST       0.57      0.75      0.65        16\n     B-MEDIA       0.95      0.96      0.96       653\n     I-MEDIA       0.97      0.97      0.97       989\n      B-MYTH       0.78      0.88      0.83        60\n      I-MYTH       0.67      0.77      0.71        13\n     B-PLANT       0.68      0.79      0.73      1933\n     I-PLANT       0.56      0.70      0.62       842\n      B-TIME       0.84      0.87      0.86       422\n      I-TIME       0.84      0.83      0.84       234\n      B-VEHI       0.79      0.90      0.84        58\n      I-VEHI       0.94      0.84      0.89        56\n\n    accuracy                           0.98    402104\n   macro avg       0.79      0.84      0.81    402104\nweighted avg       0.98      0.98      0.98    402104\n\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# System B","metadata":{}},{"cell_type":"code","source":"# Change the original dataset as to retrieve only the entities we need\n# while setting all other entities to 0\n\nvalid_ner_tags = [1, 2, 3, 4, 5, 6, 7, 8, 13, 14]\n\n# Define a function to modify ner_tags in each sample\ndef modify_ner_tags(sample):\n    # Iterate through ner_tags and replace invalid values with 0\n    sample['ner_tags'] = [tag if tag in valid_ner_tags else 0 for tag in sample['ner_tags']]\n    return sample\n\n# Apply the modification to the entire dataset\nmodified_dataset = multinerd.map(modify_ner_tags)","metadata":{"execution":{"iopub.status.busy":"2023-12-04T23:23:03.693607Z","iopub.execute_input":"2023-12-04T23:23:03.694029Z","iopub.status.idle":"2023-12-04T23:23:30.232967Z","shell.execute_reply.started":"2023-12-04T23:23:03.693983Z","shell.execute_reply":"2023-12-04T23:23:30.231901Z"},"trusted":true},"execution_count":27,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/105024 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6981b43674f44596986b05a12a1f99ab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/26256 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a87338d02ea34c90899db702bb64e8c2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/16454 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"59b60ab4f1064173b20aaea8f5010de4"}},"metadata":{}}]},{"cell_type":"code","source":"# Apply the logic to entire dataset\n\ntokenized_data_b = modified_dataset.map(tokenize_align, batched=True)","metadata":{"execution":{"iopub.status.busy":"2023-12-04T23:23:30.241848Z","iopub.execute_input":"2023-12-04T23:23:30.242522Z","iopub.status.idle":"2023-12-04T23:23:57.138385Z","shell.execute_reply.started":"2023-12-04T23:23:30.242484Z","shell.execute_reply":"2023-12-04T23:23:57.136849Z"},"trusted":true},"execution_count":28,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/106 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"beefb376ee344932b614e949d4fdd9ac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/27 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"740f0621ec804fa8b5dc76b00ee6d3c2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/17 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b65d1604396c46f8a004e3b6b412cb3c"}},"metadata":{}}]},{"cell_type":"code","source":"# Create another label mapping but with the needed tags only\n\nnew_label_mapping = {\n    0: \"O\",\n    1: \"B-PER\",\n    2: \"I-PER\",\n    3: \"B-ORG\",\n    4: \"I-ORG\",\n    5: \"B-LOC\",\n    6: \"I-LOC\",\n    7: \"B-ANIM\",\n    8: \"I-ANIM\",\n    13: \"B-DIS\",\n    14: \"I-DIS\",\n}","metadata":{"execution":{"iopub.status.busy":"2023-12-04T23:23:57.140059Z","iopub.execute_input":"2023-12-04T23:23:57.140480Z","iopub.status.idle":"2023-12-04T23:23:57.149978Z","shell.execute_reply.started":"2023-12-04T23:23:57.140436Z","shell.execute_reply":"2023-12-04T23:23:57.148827Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"# Redefine metric custom function with new dictionary\n\ndef compute_metrics_b(eval_preds):\n    pred_logits, labels = eval_preds\n    pred_logits = np.argmax(pred_logits, axis=2)\n\n    predictions = [\n        [new_label_mapping[prediction] for (prediction, l) in zip(batch_preds, label) if l != -100] \n        for batch_preds, label in zip(pred_logits, labels)\n    ]\n\n    true_labels = [\n        [new_label_mapping[l] for (prediction, l) in zip(batch_preds, label) if l != -100] \n        for batch_preds, label in zip(pred_logits, labels)\n    ]\n\n    results = metric.compute(predictions=predictions, references=true_labels)\n\n    return {\n        \"precision\": results[\"overall_precision\"],\n        \"recall\": results[\"overall_recall\"],\n        \"f1\": results[\"overall_f1\"],\n        \"accuracy\": results[\"overall_accuracy\"],\n    }","metadata":{"execution":{"iopub.status.busy":"2023-12-04T23:23:57.151563Z","iopub.execute_input":"2023-12-04T23:23:57.152270Z","iopub.status.idle":"2023-12-04T23:23:57.174629Z","shell.execute_reply.started":"2023-12-04T23:23:57.152231Z","shell.execute_reply":"2023-12-04T23:23:57.173246Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"training_args_b = TrainingArguments(\n    output_dir=\"./fine_tune_bert_output_b\",\n    evaluation_strategy=\"steps\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    num_train_epochs=3,\n    weight_decay=0.01,\n    #logging_steps = 1000,\n    report_to=\"wandb\",\n    run_name = \"RISE_B\",\n    save_strategy=\"no\",\n)","metadata":{"execution":{"iopub.status.busy":"2023-12-04T23:23:57.176456Z","iopub.execute_input":"2023-12-04T23:23:57.177139Z","iopub.status.idle":"2023-12-04T23:23:57.189654Z","shell.execute_reply.started":"2023-12-04T23:23:57.177100Z","shell.execute_reply":"2023-12-04T23:23:57.188493Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"model_b = AutoModelForTokenClassification.from_pretrained('bert-base-cased', num_labels=15)","metadata":{"execution":{"iopub.status.busy":"2023-12-04T23:23:57.190934Z","iopub.execute_input":"2023-12-04T23:23:57.191252Z","iopub.status.idle":"2023-12-04T23:23:58.434509Z","shell.execute_reply.started":"2023-12-04T23:23:57.191227Z","shell.execute_reply":"2023-12-04T23:23:58.433217Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stderr","text":"Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer_b = Trainer(\n    model=model_b,\n    args=training_args_b,\n    train_dataset=tokenized_data_b[\"train\"],\n    eval_dataset=tokenized_data_b[\"valid\"],\n    data_collator=data_collator,\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics_b\n)\n\ntrainer_b.train()","metadata":{"execution":{"iopub.status.busy":"2023-12-04T23:23:58.435921Z","iopub.execute_input":"2023-12-04T23:23:58.436285Z","iopub.status.idle":"2023-12-05T01:03:28.614165Z","shell.execute_reply.started":"2023-12-04T23:23:58.436257Z","shell.execute_reply":"2023-12-05T01:03:28.613107Z"},"trusted":true},"execution_count":33,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='19692' max='19692' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [19692/19692 1:39:29, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>0.176500</td>\n      <td>0.064446</td>\n      <td>0.823101</td>\n      <td>0.888568</td>\n      <td>0.854583</td>\n      <td>0.975103</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.056300</td>\n      <td>0.051770</td>\n      <td>0.889522</td>\n      <td>0.891664</td>\n      <td>0.890592</td>\n      <td>0.981935</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>0.049200</td>\n      <td>0.049213</td>\n      <td>0.896246</td>\n      <td>0.887460</td>\n      <td>0.891831</td>\n      <td>0.982248</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>0.047500</td>\n      <td>0.045664</td>\n      <td>0.898012</td>\n      <td>0.907124</td>\n      <td>0.902545</td>\n      <td>0.983650</td>\n    </tr>\n    <tr>\n      <td>2500</td>\n      <td>0.043800</td>\n      <td>0.046967</td>\n      <td>0.887571</td>\n      <td>0.915303</td>\n      <td>0.901224</td>\n      <td>0.983222</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>0.041800</td>\n      <td>0.043719</td>\n      <td>0.904984</td>\n      <td>0.899346</td>\n      <td>0.902157</td>\n      <td>0.983698</td>\n    </tr>\n    <tr>\n      <td>3500</td>\n      <td>0.039100</td>\n      <td>0.041508</td>\n      <td>0.897305</td>\n      <td>0.920540</td>\n      <td>0.908774</td>\n      <td>0.984716</td>\n    </tr>\n    <tr>\n      <td>4000</td>\n      <td>0.038200</td>\n      <td>0.041052</td>\n      <td>0.922074</td>\n      <td>0.895907</td>\n      <td>0.908802</td>\n      <td>0.985027</td>\n    </tr>\n    <tr>\n      <td>4500</td>\n      <td>0.036800</td>\n      <td>0.039253</td>\n      <td>0.924844</td>\n      <td>0.906092</td>\n      <td>0.915372</td>\n      <td>0.985655</td>\n    </tr>\n    <tr>\n      <td>5000</td>\n      <td>0.034700</td>\n      <td>0.039243</td>\n      <td>0.907314</td>\n      <td>0.927878</td>\n      <td>0.917481</td>\n      <td>0.985655</td>\n    </tr>\n    <tr>\n      <td>5500</td>\n      <td>0.036900</td>\n      <td>0.039754</td>\n      <td>0.911093</td>\n      <td>0.921992</td>\n      <td>0.916510</td>\n      <td>0.985712</td>\n    </tr>\n    <tr>\n      <td>6000</td>\n      <td>0.036400</td>\n      <td>0.039024</td>\n      <td>0.909218</td>\n      <td>0.928853</td>\n      <td>0.918931</td>\n      <td>0.986075</td>\n    </tr>\n    <tr>\n      <td>6500</td>\n      <td>0.035000</td>\n      <td>0.039518</td>\n      <td>0.925641</td>\n      <td>0.910163</td>\n      <td>0.917837</td>\n      <td>0.985961</td>\n    </tr>\n    <tr>\n      <td>7000</td>\n      <td>0.024600</td>\n      <td>0.040470</td>\n      <td>0.919946</td>\n      <td>0.925203</td>\n      <td>0.922567</td>\n      <td>0.986413</td>\n    </tr>\n    <tr>\n      <td>7500</td>\n      <td>0.024000</td>\n      <td>0.039403</td>\n      <td>0.923365</td>\n      <td>0.919871</td>\n      <td>0.921614</td>\n      <td>0.986523</td>\n    </tr>\n    <tr>\n      <td>8000</td>\n      <td>0.021000</td>\n      <td>0.039801</td>\n      <td>0.919567</td>\n      <td>0.917406</td>\n      <td>0.918485</td>\n      <td>0.986147</td>\n    </tr>\n    <tr>\n      <td>8500</td>\n      <td>0.020900</td>\n      <td>0.039337</td>\n      <td>0.922688</td>\n      <td>0.927343</td>\n      <td>0.925010</td>\n      <td>0.986931</td>\n    </tr>\n    <tr>\n      <td>9000</td>\n      <td>0.024800</td>\n      <td>0.040238</td>\n      <td>0.942719</td>\n      <td>0.904850</td>\n      <td>0.923396</td>\n      <td>0.986827</td>\n    </tr>\n    <tr>\n      <td>9500</td>\n      <td>0.024800</td>\n      <td>0.039481</td>\n      <td>0.922675</td>\n      <td>0.926942</td>\n      <td>0.924803</td>\n      <td>0.986984</td>\n    </tr>\n    <tr>\n      <td>10000</td>\n      <td>0.021800</td>\n      <td>0.038321</td>\n      <td>0.932753</td>\n      <td>0.918724</td>\n      <td>0.925685</td>\n      <td>0.987041</td>\n    </tr>\n    <tr>\n      <td>10500</td>\n      <td>0.024100</td>\n      <td>0.037309</td>\n      <td>0.942016</td>\n      <td>0.905939</td>\n      <td>0.923625</td>\n      <td>0.986866</td>\n    </tr>\n    <tr>\n      <td>11000</td>\n      <td>0.019700</td>\n      <td>0.038222</td>\n      <td>0.931320</td>\n      <td>0.924610</td>\n      <td>0.927953</td>\n      <td>0.987243</td>\n    </tr>\n    <tr>\n      <td>11500</td>\n      <td>0.023900</td>\n      <td>0.037419</td>\n      <td>0.922241</td>\n      <td>0.936076</td>\n      <td>0.929107</td>\n      <td>0.987455</td>\n    </tr>\n    <tr>\n      <td>12000</td>\n      <td>0.022200</td>\n      <td>0.036457</td>\n      <td>0.930962</td>\n      <td>0.926674</td>\n      <td>0.928813</td>\n      <td>0.987632</td>\n    </tr>\n    <tr>\n      <td>12500</td>\n      <td>0.021700</td>\n      <td>0.036125</td>\n      <td>0.928360</td>\n      <td>0.927419</td>\n      <td>0.927889</td>\n      <td>0.987453</td>\n    </tr>\n    <tr>\n      <td>13000</td>\n      <td>0.021800</td>\n      <td>0.036514</td>\n      <td>0.915845</td>\n      <td>0.941293</td>\n      <td>0.928395</td>\n      <td>0.987386</td>\n    </tr>\n    <tr>\n      <td>13500</td>\n      <td>0.014900</td>\n      <td>0.040374</td>\n      <td>0.926339</td>\n      <td>0.932216</td>\n      <td>0.929268</td>\n      <td>0.987384</td>\n    </tr>\n    <tr>\n      <td>14000</td>\n      <td>0.013800</td>\n      <td>0.040595</td>\n      <td>0.928732</td>\n      <td>0.930897</td>\n      <td>0.929814</td>\n      <td>0.987645</td>\n    </tr>\n    <tr>\n      <td>14500</td>\n      <td>0.012700</td>\n      <td>0.042414</td>\n      <td>0.928733</td>\n      <td>0.930917</td>\n      <td>0.929824</td>\n      <td>0.987508</td>\n    </tr>\n    <tr>\n      <td>15000</td>\n      <td>0.012300</td>\n      <td>0.043521</td>\n      <td>0.922255</td>\n      <td>0.937395</td>\n      <td>0.929764</td>\n      <td>0.987531</td>\n    </tr>\n    <tr>\n      <td>15500</td>\n      <td>0.012100</td>\n      <td>0.043575</td>\n      <td>0.932439</td>\n      <td>0.927075</td>\n      <td>0.929749</td>\n      <td>0.987622</td>\n    </tr>\n    <tr>\n      <td>16000</td>\n      <td>0.012200</td>\n      <td>0.041770</td>\n      <td>0.929959</td>\n      <td>0.932216</td>\n      <td>0.931086</td>\n      <td>0.987826</td>\n    </tr>\n    <tr>\n      <td>16500</td>\n      <td>0.012200</td>\n      <td>0.044170</td>\n      <td>0.928362</td>\n      <td>0.931662</td>\n      <td>0.930009</td>\n      <td>0.987683</td>\n    </tr>\n    <tr>\n      <td>17000</td>\n      <td>0.011500</td>\n      <td>0.043344</td>\n      <td>0.925991</td>\n      <td>0.935618</td>\n      <td>0.930779</td>\n      <td>0.987763</td>\n    </tr>\n    <tr>\n      <td>17500</td>\n      <td>0.011100</td>\n      <td>0.043898</td>\n      <td>0.926931</td>\n      <td>0.934318</td>\n      <td>0.930610</td>\n      <td>0.987715</td>\n    </tr>\n    <tr>\n      <td>18000</td>\n      <td>0.012600</td>\n      <td>0.043130</td>\n      <td>0.929478</td>\n      <td>0.930917</td>\n      <td>0.930197</td>\n      <td>0.987714</td>\n    </tr>\n    <tr>\n      <td>18500</td>\n      <td>0.011900</td>\n      <td>0.043795</td>\n      <td>0.927906</td>\n      <td>0.933191</td>\n      <td>0.930541</td>\n      <td>0.987716</td>\n    </tr>\n    <tr>\n      <td>19000</td>\n      <td>0.011000</td>\n      <td>0.043198</td>\n      <td>0.930504</td>\n      <td>0.932140</td>\n      <td>0.931321</td>\n      <td>0.987806</td>\n    </tr>\n    <tr>\n      <td>19500</td>\n      <td>0.012600</td>\n      <td>0.042606</td>\n      <td>0.929616</td>\n      <td>0.932636</td>\n      <td>0.931124</td>\n      <td>0.987810</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=19692, training_loss=0.028760366073692086, metrics={'train_runtime': 5969.4722, 'train_samples_per_second': 52.781, 'train_steps_per_second': 3.299, 'total_flos': 9101978528338080.0, 'train_loss': 0.028760366073692086, 'epoch': 3.0})"},"metadata":{}}]},{"cell_type":"code","source":"results_b = trainer_b.predict(tokenized_data_b[\"test\"])","metadata":{"execution":{"iopub.status.busy":"2023-12-05T01:03:28.615512Z","iopub.execute_input":"2023-12-05T01:03:28.615872Z","iopub.status.idle":"2023-12-05T01:04:19.153462Z","shell.execute_reply.started":"2023-12-05T01:03:28.615840Z","shell.execute_reply":"2023-12-05T01:04:19.152212Z"},"trusted":true},"execution_count":34,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}}]},{"cell_type":"code","source":"pred_logits, labels = results_b.predictions, results_b.label_ids\npred_logits = np.argmax(pred_logits, axis=2)\n\n# Flatten the predictions and true labels\nflat_true_labels = [label for sequence_labels in labels for label in sequence_labels]\nflat_pred_labels = [label for sequence_labels in pred_logits for label in sequence_labels]\n\n# Ignore special tokens (-100) during evaluation\nvalid_indices = [index for index, label in enumerate(flat_true_labels) if label != -100]\n\n# Use the sklearn classification_report function with label_mapping\nreport_b = classification_report(\n    np.array(flat_true_labels)[valid_indices],\n    np.array(flat_pred_labels)[valid_indices],\n    target_names=list(new_label_mapping.values())\n)\n\nprint(report_b)","metadata":{"execution":{"iopub.status.busy":"2023-12-05T01:04:19.154777Z","iopub.execute_input":"2023-12-05T01:04:19.155097Z","iopub.status.idle":"2023-12-05T01:04:21.571875Z","shell.execute_reply.started":"2023-12-05T01:04:19.155070Z","shell.execute_reply":"2023-12-05T01:04:21.570723Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           O       1.00      0.99      0.99    337859\n       B-PER       0.99      0.99      0.99      7354\n       I-PER       1.00      1.00      1.00     11509\n       B-ORG       0.98      0.98      0.98      5131\n       I-ORG       0.99      0.99      0.99      5693\n       B-LOC       1.00      0.99      1.00     19489\n       I-LOC       0.99      1.00      0.99      7129\n      B-ANIM       0.75      0.78      0.77      3351\n      I-ANIM       0.71      0.76      0.74      1658\n       B-DIS       0.80      0.83      0.82      2014\n       I-DIS       0.78      0.79      0.78       917\n\n    accuracy                           0.99    402104\n   macro avg       0.91      0.92      0.91    402104\nweighted avg       0.99      0.99      0.99    402104\n\n","output_type":"stream"}]}]}